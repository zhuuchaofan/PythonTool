import os
import re
import shutil
import openpyxl
import logging
import time
from collections import defaultdict
from datetime import datetime
import xlwings as xw

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
BASE_DIR = r"C:\Users\zhu-chaofan\Downloads"
JCL_DIR = os.path.join(BASE_DIR, r"JCL\JCL")  # JCL æ ¹ç›®å½•

SOURCE_FILE_NAME = "DSN_Final.xlsx"
OUTPUT_FILE_NAME = f"AssetList_Lineage_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
LOG_FILE_NAME = f"Process_Log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

SOURCE_PATH = os.path.join(BASE_DIR, SOURCE_FILE_NAME)
TARGET_PATH = os.path.join(BASE_DIR, OUTPUT_FILE_NAME)
LOG_PATH = os.path.join(BASE_DIR, LOG_FILE_NAME)

# ğŸ”¥ æ ¸å¿ƒé…ç½®ï¼šè¯·ç¡®ä¿ Excel é‡ŒçœŸçš„æœ‰è¿™ä¸ªåå­—çš„ Sheet
TARGET_SHEET_NAME = "Sheet2"

# æ‰¹å¤„ç†å¤§å°
BATCH_SIZE = 1000

# --- Excel è¯»å–åˆ— definition (1-based) ---
COL_JCL_NAME = 3   # Cåˆ—: JCLå
COL_DATASET = 7    # Gåˆ—: Datasetå
COL_RECFM = 12     # Låˆ—: RECFM (ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å¤„ç†)
COL_LRECL = 13     # Måˆ—
COL_BLKSIZE = 14   # Nåˆ—

# ================= ğŸ“ æ—¥å¿—æ¨¡å— =================
def setup_logger(log_file_path):
    logger = logging.getLogger("Processor")
    logger.setLevel(logging.INFO)
    if logger.handlers: logger.handlers.clear()
    
    fh = logging.FileHandler(log_file_path, mode='w', encoding='utf-8')
    fh.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(fh)
    
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter('%(asctime)s - %(message)s', datefmt='%H:%M:%S'))
    logger.addHandler(ch)
    return logger

logger = setup_logger(LOG_PATH)

# ================= ğŸ” è¾…åŠ©æ¨¡å—: å»ºç«‹æ–‡ä»¶ç´¢å¼• =================
def build_filename_index(root_dir):
    """é€’å½’éå†ç›®å½•ï¼Œå»ºç«‹ {æ–‡ä»¶å(æ— åç¼€): ç»å¯¹è·¯å¾„} æ˜ å°„"""
    logger.info(f"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨å»ºç«‹æ–‡ä»¶ç´¢å¼• (æ‰«æç›®å½•: {root_dir})...")
    file_map = {}
    count = 0
    for root, dirs, files in os.walk(root_dir):
        for file in files:
            name_no_ext = os.path.splitext(file)[0]
            full_path = os.path.join(root, file)
            if name_no_ext not in file_map:
                file_map[name_no_ext] = full_path
            count += 1
    logger.info(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆã€‚æ‰«ææ–‡ä»¶æ€»æ•°: {count}")
    return file_map

# ================= ğŸ§© JCL è§£æå™¨ (å…¨é‡æ•æ‰) =================
class JCLParser:
    def __init__(self, filepath):
        self.filepath = filepath
        # ç»“æ„: { "STEPå": { "PGM": "XXX", "DDS": [ {name, dsn, ...} ] } }
        self.steps = {} 
        self._load_and_parse()

    def _load_and_parse(self):
        try:
            with open(self.filepath, 'r', encoding='utf-8', errors='ignore') as f:
                raw_content = f.read()
            normalized_lines = self._normalize_jcl(raw_content)
            self._parse_lines(normalized_lines)
        except Exception as e:
            logger.error(f"âŒ è¯»å– JCL å¤±è´¥: {os.path.basename(self.filepath)} - {e}")

    def _normalize_jcl(self, content):
        """æ¸…æ´— JCLï¼Œå¤„ç†æ–­è¡Œæ‹¼æ¥"""
        lines = content.split('\n')
        cleaned_lines = []
        buffer = ""
        for line in lines:
            line = line.strip()
            if not line or line.startswith('//*') or not line.startswith('//'): continue
            if line.endswith(','):
                if buffer:
                    clean_segment = re.sub(r'^//\s*', '', line)
                    buffer += clean_segment
                else:
                    buffer = line
            else:
                if buffer:
                    clean_segment = re.sub(r'^//\s*', '', line)
                    cleaned_lines.append(buffer + clean_segment)
                    buffer = ""
                else:
                    cleaned_lines.append(line)
        return cleaned_lines

    def _parse_lines(self, lines):
        """
        è¯†åˆ«æ‰€æœ‰ STEP å’Œ DDã€‚
        ä¸å†è¿‡æ»¤é SORT ç¨‹åºï¼Œåªè¦æ˜¯ STEP éƒ½è®°å½•ã€‚
        """
        current_step_name = None
        
        re_step = re.compile(r'^//(\S+)\s+EXEC\s+PGM=([A-Z0-9#@$]+)', re.IGNORECASE)
        re_dd = re.compile(r'^//(\S+)\s+DD\s+', re.IGNORECASE)

        for line in lines:
            # 1. STEP è¯†åˆ«
            step_match = re_step.search(line)
            if step_match:
                step_name = step_match.group(1)
                pgm_name = step_match.group(2).upper()
                
                current_step_name = step_name
                self.steps[step_name] = {
                    "PGM": pgm_name,
                    "DDS": []
                }
                continue

            # 2. DD è¯†åˆ« (åªè¦åœ¨ Step å†…éƒ½æŠ“)
            if current_step_name:
                dd_match = re_dd.search(line)
                if dd_match:
                    dd_name = dd_match.group(1).upper()
                    dsn = self._extract_param(line, "DSN")
                    if not dsn: continue
                    
                    attrs = {
                        "DD": dd_name,
                        "DSN": dsn,
                        "RECFM": self._extract_param(line, "RECFM"),
                        "LRECL": self._extract_param(line, "LRECL"),
                        "BLKSIZE": self._extract_param(line, "BLKSIZE")
                    }
                    self.steps[current_step_name]["DDS"].append(attrs)

    def _extract_param(self, line, key):
        match = re.search(f"{key}=([\\w\\.\\$#@\\(\\)]+)", line, re.IGNORECASE)
        if match: return match.group(1).replace('(', '').replace(')', '')
        return None

# ================= ğŸ§  ä¸šåŠ¡æ¨ç†æœº (åˆ†çº§ç­–ç•¥) =================
class AttributeResolver:
    def __init__(self, group_rows):
        self.dsn_map = {r['dataset']: r for r in group_rows if r['dataset']}
        self.SORT_PGM_LIST = {'SORT', 'ICEMAN', 'DFSORT', 'SYNCSORT', 'IEBGENER', 'ICEGENER'}
    
    def resolve(self, target_dsn, jcl_parser):
        if not jcl_parser or not jcl_parser.steps: 
            return None, "No Steps found"

        fallback_match = None # å…œåº•æ–¹æ¡ˆ (éSORTï¼Œæˆ–æ‰¾ä¸åˆ°è¡€ç¼˜çš„å¼•ç”¨)

        # éå†æ‰€æœ‰ Step
        for step_name, step_data in jcl_parser.steps.items():
            pgm = step_data["PGM"]
            
            # åœ¨å½“å‰ Step æ‰¾ç›®æ ‡ DSN
            # (å¦‚æœä¸€ä¸ª Step æœ‰å¤šä¸ªåŒå DSNï¼Œè¿™é‡Œå–ç¬¬ä¸€ä¸ª)
            target_dd = next((dd for dd in step_data["DDS"] if dd["DSN"] == target_dsn), None)
            
            if not target_dd: continue

            # === åŸºç¡€å…ƒæ•°æ® (åªè¦æ‰¾åˆ°äº†ï¼Œå°±èƒ½å¡« AG~AJ) ===
            meta_info = {
                "STEP": step_name,
                "PGM": pgm,
                "DD": target_dd["DD"]
            }
            
            # ç­–ç•¥ï¼šå…ˆè®°å½•ä¸€ä¸ªâ€œå…œåº•ç»“æœâ€ã€‚
            # å¦‚æœåé¢ä¹Ÿæ²¡å‘ç°è¿™æ˜¯ä¸ª SORT è¾“å‡ºï¼Œå°±è¿”å›è¿™ä¸ªç»“æœã€‚
            if not fallback_match:
                fallback_match = ({
                    "Z": "N/A (Ref Only)",    # Z: ä»…å¼•ç”¨ï¼Œæ— è¡€ç¼˜
                    "AA": target_dd["RECFM"], # AA: ä¹Ÿè®¸ JCL é‡Œå†™äº†
                    "AB": target_dd["LRECL"], # AB
                    "AC": target_dd["BLKSIZE"], # AC
                    "META": meta_info,
                    "STATUS": "Done (Ref)"    # AF: çŠ¶æ€
                }, "Reference Found")

            # === é«˜çº§é€»è¾‘: åªæœ‰ SORT ç¨‹åºæ‰å°è¯•æ¨å¯¼è¡€ç¼˜ ===
            if pgm in self.SORT_PGM_LIST:
                dd_name = target_dd["DD"]
                is_output = dd_name.startswith("SORTOUT") or dd_name == "SYSUT2"
                
                if is_output:
                    # Logic A: æ˜¾å¼å®šä¹‰ (æœ€é«˜ä¼˜å…ˆçº§ä¹‹ä¸€)
                    if target_dd.get("LRECL") and target_dd.get("RECFM"):
                         return {
                            "Z": "N/A (Explicit)",
                            "AA": target_dd["RECFM"],
                            "AB": target_dd["LRECL"],
                            "AC": target_dd.get("BLKSIZE", ""),
                            "META": meta_info,
                            "STATUS": "Done (Explicit)"
                        }, "Sort Explicit"

                    # Logic B: ç»§æ‰¿è‡ªè¾“å…¥ (æœ€é«˜ä¼˜å…ˆçº§ä¹‹äºŒ)
                    input_candidates = [d for d in step_data["DDS"] 
                                        if not (d["DD"].startswith("SORTOUT") or d["DD"] == "SYSUT2")]
                    
                    if input_candidates:
                        first_input = input_candidates[0]
                        source_dsn = first_input["DSN"]
                        
                        if source_dsn in self.dsn_map:
                            src_row = self.dsn_map[source_dsn]
                            return {
                                "Z": source_dsn, 
                                "AA": src_row['recfm_val'],
                                "AB": src_row['lrecl_val'],
                                "AC": src_row['blksize_val'],
                                "META": meta_info,
                                "STATUS": "Done (Inherited)"
                            }, "Sort Inherited"
        
        # å¾ªç¯ç»“æŸï¼Œå¦‚æœæ²¡æ‰¾åˆ°â€œé«˜çº§è¡€ç¼˜â€ï¼Œä½†æ‰¾åˆ°äº†â€œæ™®é€šå¼•ç”¨â€ï¼Œè¿”å›å…œåº•
        if fallback_match:
            return fallback_match
            
        return None, "Not found in JCL"

# ================= ğŸš€ ä¸»æµç¨‹ =================
def main():
    start_time = time.time()
    logger.info(f"ğŸš€ ä»»åŠ¡å¯åŠ¨ | {datetime.now()}")

    if not os.path.exists(SOURCE_PATH):
        logger.error(f"âŒ æ‰¾ä¸åˆ°æºæ–‡ä»¶: {SOURCE_PATH}"); return
    
    jcl_path_map = build_filename_index(JCL_DIR)
    
    logger.info(f"ğŸ“‚ å¤åˆ¶æ–‡ä»¶: {SOURCE_FILE_NAME} -> {OUTPUT_FILE_NAME}")
    shutil.copy2(SOURCE_PATH, TARGET_PATH)

    # --- Phase 1: è¯»å– Excel ---
    logger.info(f"ğŸ‘€ [Phase 1] è¯»å–æ•°æ® (Sheet: {TARGET_SHEET_NAME})...")
    wb_reader = openpyxl.load_workbook(TARGET_PATH, data_only=True, read_only=True)
    try:
        ws_reader = wb_reader[TARGET_SHEET_NAME]
    except KeyError:
        logger.error(f"âŒ Excel ä¸­æ‰¾ä¸åˆ°åä¸º '{TARGET_SHEET_NAME}' çš„ Sheetï¼"); return

    groups = defaultdict(list)
    row_counter = 0
    beginRow = 108415  # æ•°æ®ä»ç¬¬108415è¡Œå¼€å§‹

    for row in ws_reader.iter_rows(min_row=beginRow, values_only=True):
        row_counter += 1
        if row_counter % 50000 == 0: logger.info(f"   ...å·²æ‰«æ {row_counter} è¡Œ")
        try:
            if len(row) < max(COL_JCL_NAME, COL_DATASET, COL_RECFM): continue
            jcl = row[COL_JCL_NAME-1]
            if not jcl: continue
            
            recfm_val = row[COL_RECFM-1]
            s_recfm = str(recfm_val).strip() if recfm_val is not None else ""
            if s_recfm.endswith(".0"): s_recfm = s_recfm[:-2]
            
            needs_process = (s_recfm == "0" or s_recfm == "")

            groups[jcl].append({
                "row_idx": row_counter + beginRow - 1,
                "dataset": row[COL_DATASET-1],
                "recfm_val": s_recfm,
                "lrecl_val": row[COL_LRECL-1],
                "blksize_val": row[COL_BLKSIZE-1],
                "needs_process": needs_process
            })
        except Exception: continue
    wb_reader.close()
    logger.info(f"âœ… æ‰«æå®Œæˆã€‚å‘ç° JCL ç»„æ•°: {len(groups)}")

    # --- Phase 2: è®¡ç®—é€»è¾‘ ---
    logger.info("ğŸ§  [Phase 2] è§£æ JCL å¹¶æ„å»ºè¡€ç¼˜/å…ƒæ•°æ®...")
    updates_buffer = [] 
    jcl_cache = {}
    
    for jcl_name, rows in groups.items():
        target_rows = [r for r in rows if r['needs_process']]
        if not target_rows: continue
        
        real_path = jcl_path_map.get(jcl_name)
        if not real_path: continue

        if jcl_name not in jcl_cache: jcl_cache[jcl_name] = JCLParser(real_path)
        
        parser = jcl_cache[jcl_name]
        resolver = AttributeResolver(rows)

        for target in target_rows:
            res_data, status = resolver.resolve(target['dataset'], parser)
            if res_data:
                meta = res_data.get("META", {})
                # ä¸ºé˜²æ­¢ None å€¼å†™å…¥æŠ¥é”™ï¼Œè½¬æ¢ä¸º ""
                safe_val = lambda v: v if v else ""
                
                updates_buffer.append({
                    "row": target['row_idx'],
                    # Z ~ AC
                    "vals_attr": [
                        safe_val(res_data["Z"]), 
                        safe_val(res_data["AA"]), 
                        safe_val(res_data["AB"]), 
                        safe_val(res_data["AC"])
                    ],
                    # AF ~ AJ
                    "vals_meta": [
                        res_data.get("STATUS", "Done"), # AF: æ ‡è®°çŠ¶æ€
                        jcl_name,                       # AG: JCLå
                        safe_val(meta.get("STEP")),     # AH: STEP
                        safe_val(meta.get("PGM")),      # AI: PGM
                        safe_val(meta.get("DD"))        # AJ: DD
                    ]
                })

    # --- Phase 3: åˆ†æ‰¹å›å†™ ---
    if updates_buffer:
        total = len(updates_buffer)
        logger.info(f"âœï¸ [Phase 3] å¯åŠ¨å›å¡«ï¼Œå…± {total} æ¡æ•°æ® (Sheet: {TARGET_SHEET_NAME})")
        
        app = xw.App(visible=True)
        app.screen_updating = False
        app.display_alerts = False
        
        try:
            wb = app.books.open(TARGET_PATH)
            app.calculation = 'manual' # å…³é—­è‡ªåŠ¨è®¡ç®—
            
            try: ws = wb.sheets[TARGET_SHEET_NAME]
            except: ws = wb.sheets[0]

            for start_idx in range(0, total, BATCH_SIZE):
                end_idx = min(start_idx + BATCH_SIZE, total)
                current_batch = updates_buffer[start_idx : end_idx]
                
                print(f"\n--- âš¡ æ­£åœ¨å¤„ç†ç¬¬ {start_idx + 1} åˆ° {end_idx} è¡Œ ---")
                t0 = time.time()
                
                for i, item in enumerate(current_batch):
                    r = item["row"]
                    # 1. å¡«ç‰©ç†å±æ€§ (Z-AC) => Zåˆ—æ˜¯ç¬¬26åˆ—
                    ws.range((r, 26)).value = item["vals_attr"]
                    
                    # 2. å¡«å…ƒæ•°æ® (AF-AJ) => AFåˆ—æ˜¯ç¬¬32åˆ—
                    # AF=32, AG=33, AH=34, AI=35, AJ=36
                    ws.range((r, 32)).value = item["vals_meta"]
                    
                    if i % 50 == 0: print(f"\r   ... è¿›åº¦: {i}/{len(current_batch)}", end="")
                
                print(f"\n   â±ï¸ æœ¬æ‰¹è€—æ—¶: {time.time() - t0:.2f}s")
                wb.save()
                
                if end_idx < total:
                    # âš ï¸ æ³¨æ„: è‡ªåŠ¨åŒ–è¿è¡Œæ—¶å»ºè®®æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ input
                    if input(f"   â“ ç»§ç»­? [Y/n] >> ").strip().lower() == 'n': break
        
        except Exception as e:
            logger.error(f"âŒ å¼‚å¸¸: {e}")
            import traceback; traceback.print_exc()
        finally:
            try:
                app.calculation = 'automatic' # æ¢å¤è®¾ç½®
                app.screen_updating = True
                wb.close()
                app.quit()
                logger.info("ğŸ‘‹ å®Œæˆ")
            except: pass
    else:
        logger.info("âš ï¸ æ²¡æœ‰æ•°æ®æ›´æ–°ã€‚")

    logger.info(f"ğŸ æ€»è€—æ—¶: {time.time() - start_time:.2f}s")

if __name__ == "__main__":
    main()